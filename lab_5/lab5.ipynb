{
  "cells": [
    {
      "cell_type": "code",
      "id": "l9qE2uIWGWSRsdIBTDtaEk59",
      "metadata": {
        "tags": [],
        "id": "l9qE2uIWGWSRsdIBTDtaEk59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877
        },
        "outputId": "18ed7d42-d725-42f7-c97f-0c5b962c1cf2",
        "collapsed": true
      },
      "source": [
        "pip install --upgrade google-genai requests googlemaps"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-genai in /usr/local/lib/python3.12/dist-packages (1.53.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Collecting requests\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting googlemaps\n",
            "  Downloading googlemaps-4.10.0.tar.gz (33 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (4.11.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-auth[requests]<3.0.0,>=2.14.1->google-genai) (2.38.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.11.10)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai) (8.5.0)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (15.0.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai) (4.9.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.4.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai) (0.6.1)\n",
            "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: googlemaps\n",
            "  Building wheel for googlemaps (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googlemaps: filename=googlemaps-4.10.0-py3-none-any.whl size=40714 sha256=8730b596960d7249a02271a2e13d292016ff5bf40717668d36c32f6df8b6eaeb\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/6a/a7/bbc6f5c200032025ee655deb5e163ce8594fa05e67d973aad6\n",
            "Successfully built googlemaps\n",
            "Installing collected packages: requests, googlemaps\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed googlemaps-4.10.0 requests-2.32.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "requests"
                ]
              },
              "id": "a33518723d0445f1b9aba41cf7612564"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "GOOGLE_API_KEY = \"AIzaSyDR3ZS-yZTpO8CkVd1YMLbKzGPm8MGTy8w\"\n",
        "\n",
        "# ‚ö†Ô∏è Replace with your city and state\n",
        "CITY = \"Denver\"\n",
        "STATE = \"CO\"\n",
        "\n",
        "# NOAA requires a User-Agent header. Use an email or project name.\n",
        "# It helps them contact you if there's an issue.\n",
        "NOAA_USER_AGENT = \"MyWeatherApp/1.0 (mike@gameplan.tech)\"\n",
        "\n",
        "\n",
        "import googlemaps\n",
        "import requests\n",
        "\n",
        "def get_lat_long_from_city(city: str, state: str) -> tuple[float, float] | None:\n",
        "    \"\"\"Uses Google Geocoding API to get latitude and longitude.\"\"\"\n",
        "    try:\n",
        "        gmaps = googlemaps.Client(key=GOOGLE_API_KEY)\n",
        "\n",
        "        # Combine city and state into a single address string\n",
        "        address = f\"{city}, {state}, USA\"\n",
        "\n",
        "        # Geocode the address\n",
        "        geocode_result = gmaps.geocode(address)\n",
        "\n",
        "        if geocode_result:\n",
        "            location = geocode_result[0]['geometry']['location']\n",
        "            latitude = location['lat']\n",
        "            longitude = location['lng']\n",
        "            # print(f\"‚úÖ Geocoding successful: {city}, {state} is at Lat: {latitude}, Long: {longitude}\")\n",
        "            return latitude, longitude\n",
        "        else:\n",
        "            print(f\"‚ùå Geocoding failed: Could not find coordinates for {city}, {state}.\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå An error occurred during geocoding: {e}\")\n",
        "        return None\n",
        "\n",
        "# --- Execution for Geocoding ---\n",
        "coordinates = get_lat_long_from_city(CITY, STATE)\n"
      ],
      "metadata": {
        "id": "WXPeo5PVLwnV",
        "cellView": "form"
      },
      "id": "WXPeo5PVLwnV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "def get_grid_points(latitude: float, longitude: float, user_agent: str) -> tuple[str, int, int] | None:\n",
        "    \"\"\"Uses NOAA /points endpoint to get WFO and grid points.\"\"\"\n",
        "    try:\n",
        "        # round to avoid handling redirect from API w less precision\n",
        "        #\n",
        "        points_url = f\"https://api.weather.gov/points/{latitude:.4f},{longitude:.4f}\"\n",
        "        headers = {'User-Agent': user_agent}\n",
        "\n",
        "        response = requests.get(points_url, headers=headers)\n",
        "        response.raise_for_status() # Raises an HTTPError for bad responses (4xx or 5xx)\n",
        "\n",
        "        data = response.json()\n",
        "        properties = data['properties']\n",
        "\n",
        "        wfo = properties['cwa']\n",
        "        grid_x = properties['gridX']\n",
        "        grid_y = properties['gridY']\n",
        "\n",
        "        # print(f\"‚úÖ Grid points successful: WFO: {wfo}, GridX: {grid_x}, GridY: {grid_y}\")\n",
        "        return wfo, grid_x, grid_y\n",
        "\n",
        "    except requests.exceptions.HTTPError as err:\n",
        "        print(f\"‚ùå NOAA API failed (HTTP Error): {err}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå An error occurred getting grid points: {e}\")\n",
        "        return None\n",
        "\n",
        "# --- Execution for Grid Points ---\n",
        "if coordinates:\n",
        "    lat, lon = coordinates\n",
        "    grid_data = get_grid_points(lat, lon, NOAA_USER_AGENT)\n",
        "else:\n",
        "    grid_data = None"
      ],
      "metadata": {
        "id": "Ir9P3YULMhx_",
        "cellView": "form"
      },
      "id": "Ir9P3YULMhx_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "def get_todays_forecast(wfo: str, grid_x: int, grid_y: int, user_agent: str):\n",
        "    \"\"\"Uses NOAA /gridpoints endpoint to get the daily forecast and prints 'Today's' forecast.\"\"\"\n",
        "    if not wfo or not grid_x or not grid_y:\n",
        "        print(\"‚ùå Cannot fetch forecast without valid grid data.\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        # Construct the final forecast URL\n",
        "        forecast_url = f\"https://api.weather.gov/gridpoints/{wfo}/{grid_x},{grid_y}/forecast\"\n",
        "        headers = {'User-Agent': user_agent}\n",
        "\n",
        "        response = requests.get(forecast_url, headers=headers)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        data = response.json()\n",
        "        periods = data['properties']['periods']\n",
        "\n",
        "        if periods:\n",
        "            # The first period is usually 'Today' or the current period\n",
        "            today_forecast = periods[0]\n",
        "\n",
        "            # print(\"\\n--- ‚òÄÔ∏è Today's Forecast ---\")\n",
        "            # print(f\"**Period:** {today_forecast['name']}\")\n",
        "            # print(f\"**Temperature:** {today_forecast['temperature']}¬∞{today_forecast['temperatureUnit']}\")\n",
        "            # print(f\"**Wind:** {today_forecast['windSpeed']} from {today_forecast['windDirection']}\")\n",
        "            # print(f\"**Details:** {today_forecast['detailedForecast']}\")\n",
        "            forecast = \"\\n--- ‚òÄÔ∏è Today's Forecast ---\"\n",
        "            forecast += f\"**Period:** {today_forecast['name']}\"\n",
        "            forecast += f\"**Temperature:** {today_forecast['temperature']}¬∞{today_forecast['temperatureUnit']}\"\n",
        "            forecast += f\"**Wind:** {today_forecast['windSpeed']} from {today_forecast['windDirection']}\"\n",
        "            forecast += f\"**Details:** {today_forecast['detailedForecast']}\"\n",
        "            return forecast\n",
        "        else:\n",
        "            print(\"‚ùå Forecast data is empty.\")\n",
        "            return None\n",
        "\n",
        "    except requests.exceptions.HTTPError as err:\n",
        "        print(f\"‚ùå NOAA API failed (HTTP Error): {err}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå An error occurred getting the forecast: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "iRewnqTiM8zp",
        "cellView": "form"
      },
      "id": "iRewnqTiM8zp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "def get_weather_from_city_state(city: str, state: str):\n",
        "  \"\"\"\n",
        "  Retrieves and prints the current weather forecast for a given city and state.\n",
        "\n",
        "  This function first converts the city and state names into geographic\n",
        "  coordinates (latitude and longitude). It then uses these coordinates\n",
        "  to determine the National Weather Service (NWS) forecast office (WFO)\n",
        "  and grid points. Finally, it fetches and prints today's forecast.\n",
        "\n",
        "  Args:\n",
        "      city (str): The name of the city (e.g., \"Denver\").\n",
        "      state (str): The two-letter state abbreviation (e.g., \"CO\").\n",
        "\n",
        "  Returns:\n",
        "      None: The function prints the forecast directly and does not\n",
        "            return a value.\n",
        "  \"\"\"\n",
        "  latitude, longitude = get_lat_long_from_city(city, state)\n",
        "  wfo, grid_x, grid_y = get_grid_points(latitude, longitude, NOAA_USER_AGENT)\n",
        "  print(get_todays_forecast(wfo, grid_x, grid_y, NOAA_USER_AGENT))\n",
        "\n",
        "# test functionality\n",
        "get_weather_from_city_state(\"Denver\", \"CO\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dz_Z941ANWfZ",
        "outputId": "63b37d15-2a27-4812-8144-05fc631ccb01",
        "cellView": "form"
      },
      "id": "Dz_Z941ANWfZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- ‚òÄÔ∏è Today's Forecast ---**Period:** This Afternoon**Temperature:** 32¬∞F**Wind:** 7 mph from NNE**Details:** Snow likely. Cloudy. High near 32, with temperatures falling to around 29 in the afternoon. North northeast wind around 7 mph. Chance of precipitation is 60%. New snow accumulation of less than one inch possible.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Recursive Response Handler (FIXED) ---\n",
        "def handle_response(client: genai.Client, response: types.GenerateContentResponse, contents: list, config: types.GenerateContentConfig, model: str):\n",
        "    \"\"\"\n",
        "    Recursively processes model responses, executes function calls,\n",
        "    and updates the conversation history.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Find the Function Call Part, if it exists\n",
        "    function_call_part = None\n",
        "    if response.candidates and response.candidates[0].content and response.candidates[0].content.parts:\n",
        "        for part in response.candidates[0].content.parts:\n",
        "            if hasattr(part, 'function_call') and part.function_call:\n",
        "                function_call_part = part\n",
        "                break\n",
        "\n",
        "    has_function_calls = function_call_part is not None\n",
        "    print(f\"Checking response for function calls. Found: {has_function_calls}\")\n",
        "\n",
        "    if has_function_calls:\n",
        "        # The logic proceeds only if a function call was found\n",
        "        function_obj = function_call_part.function_call\n",
        "\n",
        "        print(f\"Model requested function call: {function_obj.name} with args: {dict(function_obj.args)}\")\n",
        "\n",
        "        # 2. Execute the function call (rest of your existing logic)\n",
        "        result = None\n",
        "        # ... (rest of your code for function execution) ...\n",
        "        # ... (inside your existing if/except blocks) ...\n",
        "\n",
        "        if function_obj.name == \"get_weather_from_city_state\":\n",
        "            print(\"MATCHED ON FUNCTION NAME ATTEMPTING EXTRACT VARIABLES\")\n",
        "            try:\n",
        "                # Extract arguments\n",
        "                city = function_obj.args[\"city\"]\n",
        "                state = function_obj.args[\"state\"]\n",
        "\n",
        "                # 2. Extract the Call ID (CRITICAL FIX)\n",
        "                # The model assigns an ID to the call (e.g., \"aaaa-bbbb-cccc\").\n",
        "                # We must echo this back.\n",
        "                call_id = getattr(function_obj, 'id', None)\n",
        "\n",
        "                # Execute the local tool function (NOTE: You'll need to define this function globally)\n",
        "                # For example:\n",
        "                # def get_weather_from_city_state(city, state):\n",
        "                #     # Placeholder logic\n",
        "                #     return f\"The weather in {city}, {state} is 70 degrees and sunny.\"\n",
        "                # -----------------------------------------------------------------------------------\n",
        "\n",
        "                # You must have the `get_weather_from_city_state` function defined in your notebook\n",
        "                # for this to execute without a NameError.\n",
        "                result_output = get_weather_from_city_state(city, state)\n",
        "                print(f\"Function executed successfully. Result: {result_output[:50]}...\")\n",
        "\n",
        "                # Create the FunctionResponse Part\n",
        "                result = types.Part.from_function_response(\n",
        "                    name=\"get_weather_from_city_state\",\n",
        "                    response={\n",
        "                        \"content\": result_output\n",
        "                    },\n",
        "                    id=call_id\n",
        "                )\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error executing function {function_obj.name}: {e}\")\n",
        "                result = None\n",
        "\n",
        "\n",
        "        if result is None:\n",
        "            logger.error(f\"Function {function_obj.name} not implemented, failed execution, or arguments were missing.\")\n",
        "            return\n",
        "\n",
        "        # 3. Append history and recurse (rest of your existing logic)\n",
        "\n",
        "        # Append the model's request (role='model' implicitly)\n",
        "        # contents.append(response.candidates[0].content)\n",
        "        sanitized_model_turn = types.Content(\n",
        "            role=\"model\",\n",
        "            parts=[function_call_part] # We use the variable we found earlier\n",
        "        )\n",
        "        contents.append(sanitized_model_turn)\n",
        "\n",
        "        # Append the tool's result (role='function' implicitly)\n",
        "        contents.append(\n",
        "            types.Content(\n",
        "                # role=\"function\",\n",
        "                role=\"tool\",\n",
        "                parts=[result]\n",
        "            )\n",
        "        )\n",
        "\n",
        "        logger.info(\"Calling model again with function result appended to history...\")\n",
        "\n",
        "        # 4. Call the model again (recursive step)\n",
        "        next_response = client.models.generate_content(\n",
        "            # model=response.model, # Use the same model as the initial call\n",
        "            model=model,\n",
        "            contents=contents,\n",
        "            config=config,\n",
        "        )\n",
        "\n",
        "        # 5. Recursively handle the next response\n",
        "        handle_response(client, next_response, contents, config, model)\n",
        "\n",
        "    # Base case: Model provides a text response (no more function calls)\n",
        "    else:\n",
        "        logger.info(\"Base case reached: Model provided a final text response.\")\n",
        "        print(\"--- Final Model Response ---\")\n",
        "        # Print the final text response\n",
        "        print(response.text)\n",
        "        return"
      ],
      "metadata": {
        "id": "e4xR32z37DDX"
      },
      "id": "e4xR32z37DDX",
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import logging\n",
        "# from google import genai\n",
        "# from google.genai import types\n",
        "# import os\n",
        "\n",
        "# # Set up logging\n",
        "# logging.basicConfig(level=logging.INFO)\n",
        "# logger = logging.getLogger(__name__)\n",
        "\n",
        "# # --- Recursive Response Handler ---\n",
        "# def handle_response(client: genai.Client, response: types.GenerateContentResponse, contents: list, config: types.GenerateContentConfig):\n",
        "#     \"\"\"\n",
        "#     Recursively processes model responses, executes function calls,\n",
        "#     and updates the conversation history.\n",
        "#     \"\"\"\n",
        "#     # print(\"WITHIN HANDLE RESPONSE - 1\")\n",
        "#     # print('=' * 50)\n",
        "#     # print(response.candidates[0])\n",
        "#     # print(\"WITHIN HANDLE RESPONSE - 2 '=' * 50\")\n",
        "#     # print('=' * 50)\n",
        "#     # print(response.candidates[0].content.parts)\n",
        "#     # print(\"WITHIN HANDLE RESPONSE - 3 '=' * 50\")\n",
        "#     # print('=' * 50)\n",
        "#     # Check for function calls using the correct path\n",
        "#     has_function_calls = (\n",
        "#         response.candidates and\n",
        "#         response.candidates[0].content and\n",
        "#         response.candidates[0].content.parts\n",
        "#     )\n",
        "\n",
        "#     print(f\"Checking response for function calls. Found: {has_function_calls}\")\n",
        "\n",
        "#     if has_function_calls:\n",
        "#         # print(\"WITHIN HANDLE RESPONSE - has_function_calls\")\n",
        "#         # print('=' * 50)\n",
        "#         fn_obj = response.candidates[0].content.parts\n",
        "#         function_obj = fn_obj[0].function_call\n",
        "#         # print(f'printing fn_obj: {fn_obj}')\n",
        "#         # print(f'printing fn_obj parts list 0: {fn_obj[0]}')\n",
        "#         # print(f'printing fn_obj parts list 0. function : {fn_obj[0].function_call}')\n",
        "#         # print(f'printing function name: {function_obj.name}')\n",
        "\n",
        "#         # function_calls = response.candidates[0].content.parts[0].function_calls\n",
        "#         # print(f'function_calls: {function_calls}')\n",
        "#         # Assuming only one function call for this demonstration\n",
        "#         # function_call = function_calls[0]\n",
        "\n",
        "#         print(f\"Model requested function call: {function_obj.name} with args: {dict(function_obj.args)}\")\n",
        "\n",
        "#         # 2. Execute the function call\n",
        "#         result = None\n",
        "\n",
        "#         if function_obj.name == \"get_weather_from_city_state\":\n",
        "#             print(\"MATCHED ON FUNCTION NAME ATTEMPTING EXTRACT VARIABLES\")\n",
        "#             try:\n",
        "#                 # Extract arguments\n",
        "#                 city = function_obj.args[\"city\"]\n",
        "#                 state = function_obj.args[\"state\"]\n",
        "\n",
        "#                 # Execute the local tool function\n",
        "#                 result_output = get_weather_from_city_state(city, state)\n",
        "#                 print(f\"Function executed successfully. Result: {result_output[:50]}...\")\n",
        "\n",
        "#                 # Create the FunctionResponse Part\n",
        "#                 result = types.Part.from_function_response(\n",
        "#                     name=\"get_weather_from_city_state\",\n",
        "#                     response={\n",
        "#                         \"content\": result_output\n",
        "#                     }\n",
        "#                 )\n",
        "#             except Exception as e:\n",
        "#                 logger.error(f\"Error executing function {function_obj.name}: {e}\")\n",
        "#                 # Set result to None to trigger the final error check\n",
        "#                 result = None\n",
        "\n",
        "\n",
        "#         if result is None:\n",
        "#             # This is the crucial log for diagnosing what the model returns if it tries\n",
        "#             # to call a function that wasn't properly passed or doesn't exist.\n",
        "#             logger.error(f\"Function {function_obj.name} not implemented, failed execution, or arguments were missing.\")\n",
        "#             return\n",
        "\n",
        "#         # 3. Append the model's function request and the tool's result to history\n",
        "\n",
        "#         # Append the model's request (role='model' implicitly)\n",
        "#         contents.append(response.candidates[0].content)\n",
        "\n",
        "#         # Append the tool's result (role='function' implicitly)\n",
        "#         contents.append(\n",
        "#             types.Content(\n",
        "#                 role=\"function\",\n",
        "#                 parts=[result]\n",
        "#             )\n",
        "#         )\n",
        "\n",
        "#         logger.info(\"Calling model again with function result appended to history...\")\n",
        "\n",
        "#         # 4. Call the model again (recursive step)\n",
        "#         next_response = client.models.generate_content(\n",
        "#             model=response.model, # Use the same model as the initial call\n",
        "#             contents=contents,\n",
        "#             config=config,\n",
        "#         )\n",
        "\n",
        "#         # 5. Recursively handle the next response\n",
        "#         handle_response(client, next_response, contents, config)\n",
        "\n",
        "#     # Base case: Model provides a text response (no more function calls)\n",
        "#     else:\n",
        "#         logger.info(\"Base case reached: Model provided a final text response.\")\n",
        "#         print(\"--- Final Model Response ---\")\n",
        "#         # Print the final text response\n",
        "#         print(response.text)\n",
        "#         return"
      ],
      "metadata": {
        "id": "iaP-HyqKsQrF"
      },
      "id": "iaP-HyqKsQrF",
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "import os\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# --- Main Generation Function ---\n",
        "def generate():\n",
        "  # 1. Initialize Client\n",
        "  logger.info(\"Initializing Gemini Client...\")\n",
        "  # NOTE: Replace 'vertexai=True' with 'api_key=os.environ.get(\"GEMINI_API_KEY\")'\n",
        "  # if you are using the public API key approach.\n",
        "  client = genai.Client(vertexai=True)\n",
        "  logger.info(\"Client initialized.\")\n",
        "\n",
        "  model = \"gemini-3-pro-preview\"\n",
        "\n",
        "  # 2. Define Contents (Mutable list for history)\n",
        "  contents = [\n",
        "    types.Content(\n",
        "      role=\"user\",\n",
        "      parts=[\n",
        "        # types.Part.from_text(text=\"\"\"What is the weather forecast for Los Angeles, CA? use the x_weather_tool\"\"\")\n",
        "        types.Part.from_text(text=\"\"\"Can you tell me about the Alaska Department of Snow? what are some facts about it\"\"\")\n",
        "      ]\n",
        "    ),\n",
        "  ]\n",
        "\n",
        "  # 3. Define Function Calling Tool (Weather)\n",
        "  logger.info(\"Defining Function Calling Tool (Weather)...\")\n",
        "  weather_tool_declaration = types.FunctionDeclaration(\n",
        "    name=\"get_weather_from_city_state\",\n",
        "    description=get_weather_from_city_state.__doc__.strip(),\n",
        "    parameters=types.Schema(\n",
        "        type=types.Type.OBJECT,\n",
        "        properties={\n",
        "            \"city\": types.Schema(type=types.Type.STRING, description=\"The name of the city, e.g., 'Denver'.\"),\n",
        "            \"state\": types.Schema(type=types.Type.STRING, description=\"The two-letter abbreviation for the state, e.g., 'CO'.\"),\n",
        "        },\n",
        "        required=[\"city\", \"state\"],\n",
        "    ),\n",
        "  )\n",
        "\n",
        "  # Tool object for function calling\n",
        "  x_weather_tool = types.Tool(\n",
        "    function_declarations=[\n",
        "        weather_tool_declaration\n",
        "    ]\n",
        "  )\n",
        "  logger.info(\"Function Calling Tool defined.\")\n",
        "\n",
        "  # 4. Define Retrieval Tool (RAG)\n",
        "  logger.info(\"Defining Retrieval Tool (RAG)...\")\n",
        "  retrieval_tool = types.Tool(\n",
        "      retrieval=types.Retrieval(\n",
        "          vertex_rag_store=types.VertexRagStore(\n",
        "              rag_resources=[\n",
        "                  types.VertexRagStoreRagResource(\n",
        "                      rag_corpus=\"projects/720196750972/locations/us-east1/ragCorpora/4749045807062188032\"\n",
        "                  )\n",
        "              ],\n",
        "          )\n",
        "      )\n",
        "  )\n",
        "  logger.info(\"Retrieval Tool defined.\")\n",
        "\n",
        "  # 5. Define GenerateContentConfig\n",
        "  logger.info(\"Defining GenerateContentConfig with combined tools list...\")\n",
        "  all_tools = [retrieval_tool, x_weather_tool]\n",
        "\n",
        "  generate_content_config = types.GenerateContentConfig(\n",
        "    temperature = 1,\n",
        "    top_p = 0.95,\n",
        "    max_output_tokens = 65535,\n",
        "    safety_settings = [types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_HATE_SPEECH\", threshold=\"OFF\"\n",
        "    ),types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_DANGEROUS_CONTENT\", threshold=\"OFF\"\n",
        "    ),types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\", threshold=\"OFF\"\n",
        "    ),types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_HARASSMENT\", threshold=\"OFF\"\n",
        "    )],\n",
        "\n",
        "    tools = all_tools,\n",
        "\n",
        "    # thinking_config=types.ThinkingConfig(\n",
        "    #   thinking_level=\"HIGH\",\n",
        "    # ),\n",
        "  )\n",
        "  logger.info(\"GenerateContentConfig defined.\")\n",
        "\n",
        "  # 6. Call generate_content (initial call)\n",
        "  logger.info(\"Calling client.models.generate_content (Initial Call)...\")\n",
        "\n",
        "  # try:\n",
        "  initial_response = client.models.generate_content(\n",
        "    model = model,\n",
        "    contents = contents,\n",
        "    config = generate_content_config,\n",
        "  )\n",
        "  logger.info(\"Initial response received.\")\n",
        "\n",
        "  # 7. Start the recursive handling process\n",
        "  handle_response(client, initial_response, contents, generate_content_config, model)\n",
        "\n",
        "  # except Exception as e:\n",
        "  #   logger.error(f\"An error occurred during content generation: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    generate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-R1TdOvsSrK",
        "outputId": "bad0ad6b-e872-4138-e1ce-9293cbc242b8"
      },
      "id": "0-R1TdOvsSrK",
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_genai.models:Tools at indices [1] are not compatible with automatic function calling (AFC). AFC is disabled. If AFC is intended, please include python callables in the tool list, and do not include function declaration in the tool list.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking response for function calls. Found: False\n",
            "--- Final Model Response ---\n",
            "Based on the provided documents, here are some facts about the Alaska Department of Snow (ADS):\n",
            "\n",
            "*   **Establishment:** The department was founded in 1959, coinciding with Alaska becoming a U.S. state.\n",
            "*   **Mission:** Its goal is to ensure safe travel and infrastructure continuity by coordinating snow removal across 650,000 square miles.\n",
            "*   **Avalanche Control:** In mountainous regions, ADS collaborates with the Alaska Department of Transportation and local authorities for controlled avalanche mitigation.\n",
            "*   **Data:** The department publishes annual snowfall reports and statistics on its website.\n",
            "*   **Employment:** Job postings for ADS are listed on the official State of Alaska jobs website.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import logging\n",
        "# from google import genai\n",
        "# from google.genai import types\n",
        "# import os\n",
        "\n",
        "# # Set up logging\n",
        "# logging.basicConfig(level=logging.INFO)\n",
        "# logger = logging.getLogger(__name__)\n",
        "\n",
        "# def generate():\n",
        "#   # 1. Initialize Client\n",
        "#   logger.info(\"Initializing Gemini Client...\")\n",
        "#   client = genai.Client(vertexai=True)\n",
        "#   logger.info(\"Client initialized.\")\n",
        "\n",
        "#   model = \"gemini-3-pro-preview\"\n",
        "\n",
        "#   # 2. Define Contents\n",
        "#   contents = [\n",
        "#     types.Content(\n",
        "#       role=\"user\",\n",
        "#       parts=[\n",
        "#         types.Part.from_text(text=\"\"\"What is the weather forecast for Los Angeles, CA?\"\"\")\n",
        "#       ]\n",
        "#     ),\n",
        "#   ]\n",
        "\n",
        "#   # 3. Define Function Calling Tool (Weather)\n",
        "#   logger.info(\"Defining Function Calling Tool (Weather)...\")\n",
        "#   weather_tool_declaration = types.FunctionDeclaration(\n",
        "#     name=\"get_weather_from_city_state\",\n",
        "#     description=get_weather_from_city_state.__doc__.strip(),\n",
        "#     parameters=types.Schema(\n",
        "#         type=types.Type.OBJECT,\n",
        "#         properties={\n",
        "#             \"city\": types.Schema(type=types.Type.STRING, description=\"The name of the city, e.g., 'Denver'.\"),\n",
        "#             \"state\": types.Schema(type=types.Type.STRING, description=\"The two-letter abbreviation for the state, e.g., 'CO'.\"),\n",
        "#         },\n",
        "#         required=[\"city\", \"state\"],\n",
        "#     ),\n",
        "#   )\n",
        "\n",
        "#   # Tool object for function calling\n",
        "#   x_weather_tool = types.Tool(\n",
        "#     function_declarations=[\n",
        "#         weather_tool_declaration\n",
        "#     ]\n",
        "#   )\n",
        "#   logger.info(\"Function Calling Tool defined.\")\n",
        "\n",
        "#   # 4. Define Retrieval Tool (RAG)\n",
        "#   logger.info(\"Defining Retrieval Tool (RAG)...\")\n",
        "#   # Tool object for Retrieval, using the 'retrieval' field inside the Tool.\n",
        "#   retrieval_tool = types.Tool(\n",
        "#       retrieval=types.Retrieval(\n",
        "#           vertex_rag_store=types.VertexRagStore(\n",
        "#               rag_resources=[\n",
        "#                   types.VertexRagStoreRagResource(\n",
        "#                       rag_corpus=\"projects/720196750972/locations/us-east1/ragCorpora/4749045807062188032\"\n",
        "#                   )\n",
        "#               ],\n",
        "#           )\n",
        "#       )\n",
        "#   )\n",
        "#   logger.info(\"Retrieval Tool defined.\")\n",
        "\n",
        "#   # 5. Define GenerateContentConfig\n",
        "#   logger.info(\"Defining GenerateContentConfig with combined tools list...\")\n",
        "\n",
        "#   # üåü CRITICAL FIX: The Retrieval Tool MUST be included in the 'tools' list\n",
        "#   # as a types.Tool object, NOT passed as a separate 'retrieval' parameter.\n",
        "#   all_tools = [retrieval_tool, x_weather_tool]\n",
        "\n",
        "#   generate_content_config = types.GenerateContentConfig(\n",
        "#     temperature = 1,\n",
        "#     top_p = 0.95,\n",
        "#     max_output_tokens = 65535,\n",
        "#     safety_settings = [types.SafetySetting(\n",
        "#       category=\"HARM_CATEGORY_HATE_SPEECH\", threshold=\"OFF\"\n",
        "#     ),types.SafetySetting(\n",
        "#       category=\"HARM_CATEGORY_DANGEROUS_CONTENT\", threshold=\"OFF\"\n",
        "#     ),types.SafetySetting(\n",
        "#       category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\", threshold=\"OFF\"\n",
        "#     ),types.SafetySetting(\n",
        "#       category=\"HARM_CATEGORY_HARASSMENT\", threshold=\"OFF\"\n",
        "#     )],\n",
        "\n",
        "#     # Pass all tools in the 'tools' list to satisfy Pydantic validation\n",
        "#     tools = all_tools,\n",
        "\n",
        "#     # üåü REMOVED: The 'retrieval' parameter which caused the ValidationError\n",
        "#     # retrieval = retrieval_config,\n",
        "\n",
        "#     thinking_config=types.ThinkingConfig(\n",
        "#       thinking_level=\"HIGH\",\n",
        "#     ),\n",
        "#   )\n",
        "#   logger.info(\"GenerateContentConfig defined.\")\n",
        "\n",
        "#   # 6. Call generate_content (non-streaming)\n",
        "#   logger.info(\"Calling client.models.generate_content...\")\n",
        "#   try:\n",
        "#     response = client.models.generate_content(\n",
        "#       model = model,\n",
        "#       contents = contents,\n",
        "#       config = generate_content_config,\n",
        "#     )\n",
        "#     logger.info(\"Response received.\")\n",
        "\n",
        "#     # 7. Add Logging and Print Output\n",
        "#     print(\"\\n--- Model Response ---\")\n",
        "\n",
        "#     # Log function calls\n",
        "#     if response.function_calls:\n",
        "#         logger.info(\"Model requested a function call.\")\n",
        "#         print(f\"**Function Calls:** {response.function_calls}\")\n",
        "#     else:\n",
        "#         logger.info(\"Model did not request a function call.\")\n",
        "\n",
        "#     print(f\"\\n**Response Text:** {response.text}\")\n",
        "\n",
        "#   except Exception as e:\n",
        "#     logger.error(f\"An error occurred during content generation: {e}\")\n",
        "\n",
        "# generate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHEwmGoteWKZ",
        "outputId": "aaea947a-5f7b-42cd-da3a-c7fb919cce28"
      },
      "id": "EHEwmGoteWKZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_genai.models:Tools at indices [1] are not compatible with automatic function calling (AFC). AFC is disabled. If AFC is intended, please include python callables in the tool list, and do not include function declaration in the tool list.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Model Response ---\n",
            "**Function Calls:** [FunctionCall(\n",
            "  args={\n",
            "    'city': 'Los Angeles',\n",
            "    'state': 'CA'\n",
            "  },\n",
            "  name='get_weather_from_city_state'\n",
            ")]\n",
            "\n",
            "**Response Text:** None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # export GOOGLE_CLOUD_API_KEY=\"YOUR_API_KEY\"\n",
        "\n",
        "\n",
        "# from google import genai\n",
        "# from google.genai import types\n",
        "# import base64\n",
        "# import os\n",
        "\n",
        "# from google.genai.types import FunctionDeclaration, GenerateContentConfig, Part, Tool\n",
        "\n",
        "# def generate():\n",
        "#   client = genai.Client(\n",
        "#       vertexai=True,\n",
        "#       # api_key=os.environ.get(\"GOOGLE_CLOUD_API_KEY\"),\n",
        "#   )\n",
        "\n",
        "#   model = \"gemini-3-pro-preview\"\n",
        "#   # This is the new, clean contents list\n",
        "#   contents = [\n",
        "#     types.Content(\n",
        "#       role=\"user\",\n",
        "#       parts=[\n",
        "#         types.Part.from_text(text=\"\"\"What is the weather forecast for Los Angeles, CA?\"\"\")\n",
        "#         # types.Part.from_text(text=\"\"\"Can you tell me about the alaska department of snow?\"\"\")\n",
        "#       ]\n",
        "#     ),\n",
        "#   ]\n",
        "\n",
        "#   # get_product_info = FunctionDeclaration(\n",
        "#   #   name=\"get_product_info\",\n",
        "#   #   description=\"Get the stock amount and identifier for a given product\",\n",
        "#   #   parameters={\n",
        "#   #       \"type\": \"OBJECT\",\n",
        "#   #       \"properties\": {\n",
        "#   #           \"product_name\": {\"type\": \"STRING\", \"description\": \"Product name\"}\n",
        "#   #       },\n",
        "#   #   },\n",
        "#   # )\n",
        "#   weather_tool = FunctionDeclaration(\n",
        "#     name=\"get_weather_from_city_state\",\n",
        "#     description=get_weather_from_city_state.__doc__.strip(),\n",
        "#     parameters=types.Schema(\n",
        "#         type=types.Type.OBJECT,\n",
        "#         properties={\n",
        "#             \"city\": types.Schema(type=types.Type.STRING, description=\"The name of the city, e.g., 'Denver'.\"),\n",
        "#             \"state\": types.Schema(type=types.Type.STRING, description=\"The two-letter abbreviation for the state, e.g., 'CO'.\"),\n",
        "#         },\n",
        "#         required=[\"city\", \"state\"],\n",
        "#     ),\n",
        "#   )\n",
        "\n",
        "#   # THIS MAY BE ONE LEVEL TOO NESTED\n",
        "#   #\n",
        "#   x_weather_tool = Tool(\n",
        "#     function_declarations=[\n",
        "#         weather_tool\n",
        "#     ]\n",
        "#   )\n",
        "\n",
        "# # # 1. Define the tool schema for the function\n",
        "# #   weather_tool = types.Tool(\n",
        "# #       function_declarations=[\n",
        "# #           types.FunctionDeclaration(\n",
        "# #               name=\"get_weather_from_city_state\",\n",
        "# #               description=get_weather_from_city_state.__doc__.strip(),\n",
        "# #               parameters=types.Schema(\n",
        "# #                   type=types.Type.OBJECT,\n",
        "# #                   properties={\n",
        "# #                       \"city\": types.Schema(type=types.Type.STRING, description=\"The name of the city, e.g., 'Denver'.\"),\n",
        "# #                       \"state\": types.Schema(type=types.Type.STRING, description=\"The two-letter abbreviation for the state, e.g., 'CO'.\"),\n",
        "# #                   },\n",
        "# #                   required=[\"city\", \"state\"],\n",
        "# #               ),\n",
        "# #           )\n",
        "# #       ]\n",
        "# #   )\n",
        "\n",
        "\n",
        "\n",
        "#   # 2. Define the Retrieval configuration as a Tool object\n",
        "#   retrieval_tool = types.Tool(\n",
        "#       retrieval=types.Retrieval(\n",
        "#           vertex_rag_store=types.VertexRagStore(\n",
        "#               rag_resources=[\n",
        "#                   types.VertexRagStoreRagResource(\n",
        "#                       rag_corpus=\"projects/720196750972/locations/us-east1/ragCorpora/4749045807062188032\"\n",
        "#                   )\n",
        "#               ],\n",
        "#           )\n",
        "#       )\n",
        "#   )\n",
        "\n",
        "\n",
        "#   generate_content_config = types.GenerateContentConfig(\n",
        "#     temperature = 1,\n",
        "#     top_p = 0.95,\n",
        "#     max_output_tokens = 65535,\n",
        "#     safety_settings = [types.SafetySetting(\n",
        "#       category=\"HARM_CATEGORY_HATE_SPEECH\",\n",
        "#       threshold=\"OFF\"\n",
        "#     ),types.SafetySetting(\n",
        "#       category=\"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "#       threshold=\"OFF\"\n",
        "#     ),types.SafetySetting(\n",
        "#       category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "#       threshold=\"OFF\"\n",
        "#     ),types.SafetySetting(\n",
        "#       category=\"HARM_CATEGORY_HARASSMENT\",\n",
        "#       threshold=\"OFF\"\n",
        "#     )],\n",
        "#     # tools = [retrieval_tool, weather_tool],\n",
        "#     tools = [retrieval_tool, x_weather_tool],\n",
        "#     # retrieval = retrieval_config,\n",
        "#     thinking_config=types.ThinkingConfig(\n",
        "#       thinking_level=\"HIGH\",\n",
        "#     ),\n",
        "#   )\n",
        "\n",
        "#   for chunk in client.models.generate_content_stream(\n",
        "#     model = model,\n",
        "#     contents = contents,\n",
        "#     config = generate_content_config,\n",
        "#     ):\n",
        "#     if not chunk.candidates or not chunk.candidates[0].content or not chunk.candidates[0].content.parts:\n",
        "#         continue\n",
        "#     print(chunk.text, end=\"\")\n",
        "\n",
        "# generate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9R416QjHDJq",
        "outputId": "bfe5f8d8-3b39-4321-b19e-72a7efa8dbe2"
      },
      "id": "D9R416QjHDJq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_genai.models:Tools at indices [1] are not compatible with automatic function calling. AFC will be disabled.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# backend API functionality\n"
      ],
      "metadata": {
        "id": "tBO4IUO2J5F5"
      },
      "id": "tBO4IUO2J5F5",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "lab5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}