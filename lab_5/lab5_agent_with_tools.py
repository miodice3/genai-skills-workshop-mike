# -*- coding: utf-8 -*-
"""student-01-d0ec89363b76 (Dec 4, 2025, 10:23:48â€¯AM)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/embedded/projects/qwiklabs-gcp-04-69ab7976b631/locations/us-central1/repositories/aa967f34-2501-4572-9b70-03755e9ef962
"""

# Commented out IPython magic to ensure Python compatibility.
# @title
# pip install --upgrade google-genai requests googlemaps
# %pip install --upgrade google-genai requests googlemaps google-cloud-modelarmor

# @title
GOOGLE_API_KEY = "AIzaSyA6cVm8Fld4Mov2ZDDK-ydKFVvtKKZQ4HM"
# KEY = "AIzaSyA6cVm8Fld4Mov2ZDDK-ydKFVvtKKZQ4HM"

CITY = "Denver"
STATE = "CO"

# NOAA requires a User-Agent header. Use an email or project name.
# It helps them contact you if there's an issue.
NOAA_USER_AGENT = "MyWeatherApp/1.0 (mike@gameplan.tech)"


import googlemaps
import requests

# @title
import googlemaps
import requests

# Ideally, retrieve this from a secure store like colab user_secrets
# from google.colab import userdata
# GOOGLE_API_KEY = userdata.get('my_maps_key')

def get_lat_long_from_city(city: str, state: str) -> tuple[float, float] | None:
    try:
        gmaps = googlemaps.Client(key=GOOGLE_API_KEY)
        address = f"{city}, {state}, USA"

        # Geocode the address
        geocode_result = gmaps.geocode(address)
        print(f'get_lat_long_from_city - geocode_result: {geocode_result}')

        if geocode_result:
            location = geocode_result[0]['geometry']['location']
            return location['lat'], location['lng']
        else:
            print(f"âŒ Geocoding returned 0 results for {city}, {state}.")
            return None

    except googlemaps.exceptions.ApiError as e:
        # This specific exception often contains the detailed 'status' and 'error_message'
        print(f"âŒ Google Maps API Error: {e}")
        print(f"   Status: {e.status}")
        print(f"   Message: {e.message}")
        return None
    except Exception as e:
        print(f"âŒ General Error: {e}")
        return None

# Execution
coordinates = get_lat_long_from_city("Denver", "CO")
if coordinates:
    print(f"âœ… Coordinates: {coordinates}")

# @title
def get_grid_points(latitude: float, longitude: float, user_agent: str) -> tuple[str, int, int] | None:
    """Uses NOAA /points endpoint to get WFO and grid points."""
    try:
        # round to avoid handling redirect from API w less precision
        #
        points_url = f"https://api.weather.gov/points/{latitude:.4f},{longitude:.4f}"
        headers = {'User-Agent': user_agent}

        response = requests.get(points_url, headers=headers)
        response.raise_for_status() # Raises an HTTPError for bad responses (4xx or 5xx)

        data = response.json()
        properties = data['properties']

        wfo = properties['cwa']
        grid_x = properties['gridX']
        grid_y = properties['gridY']

        # print(f"âœ… Grid points successful: WFO: {wfo}, GridX: {grid_x}, GridY: {grid_y}")
        return wfo, grid_x, grid_y

    except requests.exceptions.HTTPError as err:
        print(f"âŒ NOAA API failed (HTTP Error): {err}")
        return None
    except Exception as e:
        print(f"âŒ An error occurred getting grid points: {e}")
        return None

# --- Execution for Grid Points ---
if coordinates:
    lat, lon = coordinates
    grid_data = get_grid_points(lat, lon, NOAA_USER_AGENT)
    print(grid_data)
else:
    grid_data = None
    print("no grid data")

# @title
def get_todays_forecast(wfo: str, grid_x: int, grid_y: int, user_agent: str):
    """Uses NOAA /gridpoints endpoint to get the daily forecast and prints 'Today's' forecast."""
    if not wfo or not grid_x or not grid_y:
        print("âŒ Cannot fetch forecast without valid grid data.")
        return

    try:
        # Construct the final forecast URL
        forecast_url = f"https://api.weather.gov/gridpoints/{wfo}/{grid_x},{grid_y}/forecast"
        headers = {'User-Agent': user_agent}

        response = requests.get(forecast_url, headers=headers)
        response.raise_for_status()

        data = response.json()
        periods = data['properties']['periods']

        if periods:
            # The first period is usually 'Today' or the current period
            today_forecast = periods[0]

            # print("\n--- â˜€ï¸ Today's Forecast ---")
            # print(f"**Period:** {today_forecast['name']}")
            # print(f"**Temperature:** {today_forecast['temperature']}Â°{today_forecast['temperatureUnit']}")
            # print(f"**Wind:** {today_forecast['windSpeed']} from {today_forecast['windDirection']}")
            # print(f"**Details:** {today_forecast['detailedForecast']}")
            forecast = "\n--- â˜€ï¸ Today's Forecast ---"
            forecast += f"**Period:** {today_forecast['name']}"
            forecast += f"**Temperature:** {today_forecast['temperature']}Â°{today_forecast['temperatureUnit']}"
            forecast += f"**Wind:** {today_forecast['windSpeed']} from {today_forecast['windDirection']}"
            forecast += f"**Details:** {today_forecast['detailedForecast']}"
            return forecast
        else:
            print("âŒ Forecast data is empty.")
            return None

    except requests.exceptions.HTTPError as err:
        print(f"âŒ NOAA API failed (HTTP Error): {err}")
        return None
    except Exception as e:
        print(f"âŒ An error occurred getting the forecast: {e}")
        return None

# @title
def get_weather_from_city_state(city: str, state: str):
  """
  Retrieves and prints the current weather forecast for a given city and state.

  This function first converts the city and state names into geographic
  coordinates (latitude and longitude). It then uses these coordinates
  to determine the National Weather Service (NWS) forecast office (WFO)
  and grid points. Finally, it fetches and prints today's forecast.

  Args:
      city (str): The name of the city (e.g., "Denver").
      state (str): The two-letter state abbreviation (e.g., "CO").

  Returns:
      None: The function prints the forecast directly and does not
            return a value.
  """
  latitude, longitude = get_lat_long_from_city(city, state)
  wfo, grid_x, grid_y = get_grid_points(latitude, longitude, NOAA_USER_AGENT)
  string_forecast = get_todays_forecast(wfo, grid_x, grid_y, NOAA_USER_AGENT)
  print('logging from get_weather_from_city_state ')
  print(string_forecast)
  return string_forecast

# test functionality
get_weather_from_city_state("Denver", "CO")

# @title
import logging
from google import genai
from google.genai import types
import os

import pdb

# --- Recursive Response Handler (ROBUST FIX) ---
def handle_response(client: genai.Client, response: types.GenerateContentResponse, contents: list, config: types.GenerateContentConfig, model: str):

    # 1. Check for function calls
    function_call_part = None
    # We iterate to find the specific part containing the function call
    if response.candidates and response.candidates[0].content and response.candidates[0].content.parts:
        for part in response.candidates[0].content.parts:
            if part.function_call:
                function_call_part = part
                break

    if function_call_part:
        function_obj = function_call_part.function_call

        # --- CRITICAL: Capture the Call ID ---
        # The API requires this ID to match the response later.
        # If it's None, we default to an empty string or handle gracefully,
        # but for Gemini 1.5 it should always be present.
        call_id = getattr(function_obj, 'id', None)

        print(f"Model requested: {function_obj.name}")
        print(f"Call ID detected: {call_id}") # Debug print to verify ID exists

        result_part = None

        if function_obj.name == "get_weather_from_city_state":
            try:
                # Extract args
                args = function_obj.args
                city = args.get("city")
                state = args.get("state")

                # Execute your local function
                result_output = get_weather_from_city_state(city, state)
                print(f"Tool execution result: {str(result_output)[:50]}...")

                # --- FIX 1: Construct the Tool Response Manually ---
                # We build the object explicitly to ensure the ID is set correctly.
                result_part = types.Part(
                    function_response=types.FunctionResponse(
                        name="get_weather_from_city_state",
                        response={"content": result_output}, # Must be a dict
                        id=call_id # PASS THE ID BACK
                    )
                )
            except Exception as e:
                print(f"Error executing weather tool: {e}")

        if not result_part:
            print("No result generated from tool execution.")
            return

        # --- FIX 2: Sanitize the Model's Turn in History ---
        # Instead of reusing the raw 'function_call_part' from the API response (which can have hidden metadata),
        # we reconstruct a clean FunctionCall object for the history. This prevents 400 errors.
        clean_function_call = types.FunctionCall(
            name=function_obj.name,
            args=function_obj.args,
            id=call_id
        )

        sanitized_model_turn = types.Content(
            role="model",
            parts=[types.Part(function_call=clean_function_call)]
        )
        contents.append(sanitized_model_turn)

        # Append the Tool Response (role="tool")
        tool_turn = types.Content(
            role="tool",
            parts=[result_part]
        )
        contents.append(tool_turn)

        print("Recursively calling model with updated history...")

        # 4. Recursive Call
        try:
            # pdb.set_trace()
            # print('tool inspection 1')
            # print(config.tools)
            # print('tool inspection 2')
            # new_list = my_list[1:]
            config.tools = config.tools[1:]
            # print(config.tools)
            # print('tool inspection 3')
            # print(f'model: {model} - contents: {contents} - config: {config}')

            next_response = client.models.generate_content(
                model=model,
                contents=contents,
                config=config,
            )
            # pdb.set_trace()
            print('model queried for recursive call, now recursive call to handle_response')
            return handle_response(client, next_response, contents, config, model)
        except Exception as e:
            print(f"API Error during recursion: {e}")
            # print(contents) # Uncomment to inspect history if it fails again

    else:
        # Base case: Text response
        print("Final response received.")
        print("\n--- Final Answer ---")
        if response.text:
            print(response.text)
            return response.text

# import model armor
from google.cloud import modelarmor_v1
# support for spec MA endpoint
from google.api_core.client_options import ClientOptions

PROJECT_ID = "qwiklabs-gcp-04-69ab7976b631"
LOCATION = "global"
# MODEL_ARMOR_LOCATION = "us-east1"
MODEL_ARMOR_LOCATION = "us"

# const for template name
MODEL_ARMOR_TEMPLATE_ID = "lab-five-query-template"

MODEL_ARMOR_ENDPOINT = f"modelarmor.{MODEL_ARMOR_LOCATION}.rep.googleapis.com"
model_armor_client = modelarmor_v1.ModelArmorClient(
    client_options=ClientOptions(api_endpoint=MODEL_ARMOR_ENDPOINT)
)


def check_prompt_with_model_armor(prompt: str) -> bool:
    """
    check user prompt against Model Armor template

    Args:
        prompt: The user's input string.

    Returns:
        True if the prompt is safe to proceed, False if it should be blocked.
    """
    print(f"Checking prompt with Model Armor template: {MODEL_ARMOR_TEMPLATE_ID}...")

    # Construct the resource name for the template
    template_name = model_armor_client.template_path(
        PROJECT_ID, MODEL_ARMOR_LOCATION, MODEL_ARMOR_TEMPLATE_ID
    )

    # Prepare the prompt data object
    user_prompt_data = modelarmor_v1.DataItem(text=prompt)

    # Create the request
    ma_request = modelarmor_v1.SanitizeUserPromptRequest(
        name=template_name,
        user_prompt_data=user_prompt_data,
    )

    # Call the Model Armor service
    ma_response = model_armor_client.sanitize_user_prompt(request=ma_request)

    # Check the result. MATCH_FOUND means a filter rule was triggered.
    match_found = ma_response.sanitization_result.filter_match_state == modelarmor_v1.FilterMatchState.MATCH_FOUND

    if match_found:
        print("\nðŸš¨ Model Armor Blocked Prompt ðŸš¨")
        # Print details for debugging (optional)
        print(f"Results: {dict(ma_response.sanitization_result.filter_results)}")
        return False
    else:
        print("âœ… Model Armor Check Passed.")
        return True

# check response with model armor
MODEL_ARMOR_RESPONSE_TEMPLATE_ID = "ma-response-filter"

def check_response_with_model_armor(model_response: str) -> bool:
    """
    check response against Model Armor template

    Args:
        model_response: The model's output string.

    Returns:
        True if the response is safe to proceed, False if it should be blocked/revised.
    """
    print(f"\nChecking model response with Model Armor template: {MODEL_ARMOR_RESPONSE_TEMPLATE_ID}...")

    # Construct the resource name for the template
    template_name = model_armor_client.template_path(
        PROJECT_ID, MODEL_ARMOR_LOCATION, MODEL_ARMOR_RESPONSE_TEMPLATE_ID
    )

    # Prepare the model response data object
    model_response_data = modelarmor_v1.DataItem(text=model_response)

    # Create the request for response sanitization
    ma_request = modelarmor_v1.SanitizeModelResponseRequest(
        name=template_name,
        model_response_data=model_response_data,
    )

    # Call the Model Armor service for response check
    ma_response = model_armor_client.sanitize_model_response(request=ma_request)

    # Check the result. MATCH_FOUND means a filter rule was triggered.
    match_found = ma_response.sanitization_result.filter_match_state == modelarmor_v1.FilterMatchState.MATCH_FOUND

    if match_found:
        print("\nðŸš¨ Model Armor Blocked Response ðŸš¨")
        # Print details for debugging (optional)
        print(f"Results: {dict(ma_response.sanitization_result.filter_results)}")
        return False
    else:
        print("âœ… Model Armor Response Check Passed.")
        return True

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# --- Main Generation Function ---
def generate(user_query: str):
  # 1. Initialize Client
  client = genai.Client(vertexai=True)

  model = "gemini-2.5-pro"

  system_instructions = """You are a helpful AI assistant with access to weather information and knowledge retrieval capabilities for the Alaska Department of Snow.
  When users ask about weather, use the get_weather_from_city_state function to get accurate, current forecasts.
  For other questions, you can search through your knowledge base to provide helpful information.

  RULES:
  1. if a user asks about anything other than a weather forecast in a City and State, snow, or Alaska Department of Snow, respond with "I'm sorry I cannot help you with that."
  2. Limit your final response to 240 characters or less.
  3. Add the relevant hash tag in ALL CAPITAL LETTERS, #FORECAST, #ALASKA_DS, #USEANOTHERCHATBOT

  User Query:
  """

  enhanced_user_query = system_instructions + user_query

  # 2. Define Contents (Mutable list for history)
  contents = [
    types.Content(
      role="user",
      parts=[
        types.Part.from_text(text=user_query)
      ]
    ),
  ]

  # 3. Define Function Calling Tool (Weather)
  logger.info("Defining Function Calling Tool (Weather)...")
  weather_tool_declaration = types.FunctionDeclaration(
    name="get_weather_from_city_state",
    description=get_weather_from_city_state.__doc__.strip(),
    parameters=types.Schema(
        type=types.Type.OBJECT,
        properties={
            "city": types.Schema(type=types.Type.STRING, description="The name of the city, e.g., 'Denver'."),
            "state": types.Schema(type=types.Type.STRING, description="The two-letter abbreviation for the state, e.g., 'CO'."),
        },
        required=["city", "state"],
    ),
  )

  # Tool object for function calling
  x_weather_tool = types.Tool(
    function_declarations=[
        weather_tool_declaration
    ]
  )
  logger.info("Function Calling Tool defined.")

  # NEW RAG: rag_corpus="projects/qwiklabs-gcp-04-69ab7976b631/locations/us-east1/ragCorpora/6917529027641081856"

  # 4. Define Retrieval Tool (RAG)
  logger.info("Defining Retrieval Tool (RAG)...")
  retrieval_tool = types.Tool(
      retrieval=types.Retrieval(
          vertex_rag_store=types.VertexRagStore(
              rag_resources=[
                  types.VertexRagStoreRagResource(
                      rag_corpus="projects/qwiklabs-gcp-04-69ab7976b631/locations/us-east1/ragCorpora/6917529027641081856"
                  )
              ],
          )
      )
  )
  print("Retrieval Tool defined.")

  # 5. Define GenerateContentConfig
  logger.info("Defining GenerateContentConfig with combined tools list...")
  all_tools = [retrieval_tool, x_weather_tool]

  generate_content_config = types.GenerateContentConfig(
    temperature = 1,
    top_p = 0.95,
    max_output_tokens = 65535,
    safety_settings = [types.SafetySetting(
      category="HARM_CATEGORY_HATE_SPEECH", threshold="OFF"
    ),types.SafetySetting(
      category="HARM_CATEGORY_DANGEROUS_CONTENT", threshold="OFF"
    ),types.SafetySetting(
      category="HARM_CATEGORY_SEXUALLY_EXPLICIT", threshold="OFF"
    ),types.SafetySetting(
      category="HARM_CATEGORY_HARASSMENT", threshold="OFF"
    )],
    tools = all_tools,
  )
  logger.info("GenerateContentConfig defined.")

  # 6. Call generate_content (initial call)
  logger.info("Calling client.models.generate_content (Initial Call)...")

  if check_prompt_with_model_armor(user_query):
    # try:
    initial_response = client.models.generate_content(
      model = model,
      contents = contents,
      config = generate_content_config,
    )
    logger.info("Initial response received.")

    # 7. Start the recursive handling process
    final_response = handle_response(client, initial_response, contents, generate_content_config, model)

    print('this is final response about to check it with model armor')
    print(final_response)


    is_response_safe = check_response_with_model_armor(final_response)

    if is_response_safe:
      print('response passed model armor')
      print(final_response)
      return final_response
    else:
      print("\n[BLOCKED] The model generated an unsafe response, and it was blocked by Model Armor.")
      return None

  else:
      blocked_status = "[BLOCKED] The query was blocked by Model Armor."
      print(blocked_status)
      return blocked_status
