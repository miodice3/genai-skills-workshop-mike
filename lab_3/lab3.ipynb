{
  "cells": [
    {
      "cell_type": "code",
      "id": "w5T9qmA0sRwUSgYrhATL3wW6",
      "metadata": {
        "tags": [],
        "id": "w5T9qmA0sRwUSgYrhATL3wW6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7979aba-5e9a-4ab1-a6c3-91021be75e89"
      },
      "source": [
        "!pip install google-genai\n",
        "#"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-genai in /usr/local/lib/python3.12/dist-packages (1.52.0)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (4.11.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.38.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.11.10)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.32.4)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai) (8.5.0)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (15.0.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.5.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Python function that uses Gemini to classify user questions into one of the following\n",
        "# categories: Employment, General Information, Emergency Services, or Tax Related\n",
        "\n",
        "# Using an LLM for classification or sentiment analysis are examples\n",
        "\n",
        "import os\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "PROJECT_ID = \"qwiklabs-gcp-01-c75658565206\"\n",
        "LOCATION = \"us-west1\"\n",
        "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)\n",
        "\n",
        "def classify_user_question(prompt: str) -> str:\n",
        "  \"\"\"\n",
        "  Uses the Gemini model to classify a user question into one of four categories:\n",
        "  Employment, General Information, Emergency Services, or Tax Related.\n",
        "\n",
        "  Args:\n",
        "    prompt: The user's question as a string.\n",
        "\n",
        "  Returns:\n",
        "    The classified category as a string (e.g., 'Employment').\n",
        "  \"\"\"\n",
        "\n",
        "  # Select a suitable model for fast classification (e.g., gemini-2.5-flash)\n",
        "  model = 'gemini-2.5-flash'\n",
        "\n",
        "  # The system instruction guides the model's behavior and output format.\n",
        "  system_instruction = (\n",
        "      \"You are an expert classification system. \"\n",
        "      \"Your sole task is to classify the user's message into one of the \"\n",
        "      \"following four categories: 'Employment', 'General Information', \"\n",
        "      \"'Emergency Services', or 'Tax Related'. \"\n",
        "      \"You MUST output ONLY the name of the category.\"\n",
        "  )\n",
        "\n",
        "  response = client.models.generate_content(\n",
        "      model=model,\n",
        "      contents=f\"Message: {prompt}\",\n",
        "      config=types.Generate  ContentConfig(\n",
        "          system_instruction=system_instruction,\n",
        "          # Setting temperature to 0.0 encourages deterministic and strict classification\n",
        "          temperature=0.0\n",
        "      ),\n",
        "  )\n",
        "\n",
        "  # Clean up the response text and return the category\n",
        "  return response.text.strip()\n",
        "\n",
        "\n",
        "# --- Example Usage ---\n",
        "print(classify_user_question(\"I need to know my W-2 status.\"))\n",
        "print(classify_user_question(\"What is the capital of France?\"))\n",
        "print(classify_user_question(\"Is there a fire nearby?\"))\n",
        "print(classify_user_question(\"How do I apply for the open position?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91BgUfPmW4bP",
        "outputId": "776af8d6-beaf-49e9-a6a1-651735a059e9"
      },
      "id": "91BgUfPmW4bP",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tax Related\n",
            "General Information\n",
            "Emergency Services\n",
            "Employment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a second function that generates social media posts for government announcements like\n",
        "# weather emergencies, holidays, school closings, etc.\n",
        "\n",
        "\n",
        "def generate_government_post(prompt: str) -> str:\n",
        "  \"\"\"\n",
        "  Generates a concise, authoritative social media announcement (e.g., Tweet)\n",
        "  for public service purposes based on the user's request.\n",
        "\n",
        "  Args:\n",
        "    prompt: The core information for the announcement (e.g., \"All schools\n",
        "            are closed due to snow today\").\n",
        "\n",
        "  Returns:\n",
        "    The generated, formatted social media post.\n",
        "  \"\"\"\n",
        "  # Using a fast model for text generation\n",
        "  model = 'gemini-2.5-flash'\n",
        "\n",
        "  # The system instruction defines the persona and rules the model must follow\n",
        "  system_instruction = (\n",
        "      \"You are a public communications officer writing critical announcements \"\n",
        "      \"for social media (like Twitter/X). Your tone must be authoritative, \"\n",
        "      \"clear, and concise. All posts must be highly readable and actionable.\"\n",
        "  )\n",
        "\n",
        "  # Use few-shot prompting to guide the model on formatting and rules\n",
        "  few_shot_prompt = (\n",
        "      \"\"\"\n",
        "      # Rules:\n",
        "      1. Max character limit is 240.\n",
        "      2. Use ALL CAPS for critical information.\n",
        "      3. Include relevant hashtags like #SafetyAlert, #Weather, or #Update.\n",
        "\n",
        "      # Example Input:\n",
        "      City Hall will be closed for the holiday tomorrow.\n",
        "\n",
        "      # Example Output:\n",
        "      REMINDER: City Hall and all non-essential municipal services will be CLOSED tomorrow, Dec 25, for the holiday. Normal operations resume Wednesday. #HolidayUpdate\n",
        "\n",
        "      # Input:\n",
        "      {0}\n",
        "\n",
        "      # Output:\n",
        "      \"\"\".format(prompt)\n",
        "  )\n",
        "\n",
        "  response = client.models.generate_content(\n",
        "      model=model,\n",
        "      contents=few_shot_prompt,\n",
        "      config=types.GenerateContentConfig(\n",
        "          system_instruction=system_instruction,\n",
        "          temperature=0.7 # Allow for some creativity in phrasing\n",
        "      ),\n",
        "  )\n",
        "\n",
        "  return response.text.strip()\n",
        "\n",
        "\n",
        "# --- Example of how to use the function in your notebook ---\n",
        "print(\"--- Weather Emergency Post ---\")\n",
        "print(generate_government_post(\"A severe thunderstorm warning is in effect until 8 PM. Seek shelter immediately.\"))\n",
        "\n",
        "print(\"\\n--- School Closing Post ---\")\n",
        "print(generate_government_post(\"All district schools are closed today, Tuesday, due to a power outage.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uyoOgEHXAly",
        "outputId": "dac3aeec-b8fd-436c-9504-5c165e5c0415"
      },
      "id": "7uyoOgEHXAly",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Weather Emergency Post ---\n",
            "SEVERE THUNDERSTORM WARNING IN EFFECT UNTIL 8 PM. SEEK SHELTER IMMEDIATELY. Stay indoors, away from windows. #WeatherAlert #SafetyFirst\n",
            "\n",
            "--- School Closing Post ---\n",
            "ALERT: ALL DISTRICT SCHOOLS ARE CLOSED TODAY, TUESDAY, due to a POWER OUTAGE. NO CLASSES WILL BE HELD. #SchoolClosure #PowerOutage #SafetyAlert\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write unit tests for each function using pytest."
      ],
      "metadata": {
        "id": "nuMuC-MDXEQp"
      },
      "id": "nuMuC-MDXEQp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the Google Evaluation API to evaluate and compare Gemini responses from different\n",
        "# prompts."
      ],
      "metadata": {
        "id": "AM-FXKlsXGDa"
      },
      "id": "AM-FXKlsXGDa",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "student-01-d0ec89363b76 (Dec 2, 2025, 4:17:23â€¯PM)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}